{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# premier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "seq_1 = torch.randn(5, 128)  # 5 tweets, 128-dim embeddings\n",
    "seq_2 = torch.randn(3, 128)  # 3 tweets, 128-dim embeddings\n",
    "seq_3 = torch.randn(7, 128)  # 7 tweets, 128-dim embeddings\n",
    "\n",
    "# Pad sequences so they are the same length\n",
    "padded_seqs = pad_sequence([seq_1, seq_2, seq_3], batch_first=True) \n",
    "# shape = b_size, max_n_tweets, 128\n",
    "# avec b_size=3 et max_n_tweets=7\n",
    "\n",
    "# Create masks to identify the real data points\n",
    "lengths = [seq_1.size(0), seq_2.size(0), seq_3.size(0)]\n",
    "mask = torch.arange(padded_seqs.size(1)).unsqueeze(0) < torch.tensor(lengths).unsqueeze(1)\n",
    "\n",
    "# Example of applying a weighted average (mask-aware)\n",
    "weights = torch.randn_like(padded_seqs)\n",
    "weighted_sum = torch.sum(weights * padded_seqs * mask.unsqueeze(2), dim=1)\n",
    "average = weighted_sum / mask.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average[0] - (torch.sum((weights[0, :5] * seq_1), dim=0) / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vrai donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>c2cdr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ID_QI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2024-10-01</th>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2024-10-02</th>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2024-10-03</th>\n",
       "      <th>3</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   f1   f2   m1   m2  c2cdr\n",
       "date       ID_QI                           \n",
       "2024-10-01 1      0.1  1.1  2.1  3.3   0.56\n",
       "           1      0.2  1.2  2.2  3.4   0.56\n",
       "           2      0.3  1.3  2.3  3.5   0.57\n",
       "           2      0.4  3.3  2.4  3.1   0.57\n",
       "           1      0.5  3.4  3.3  3.2   0.56\n",
       "2024-10-02 2      0.2  3.5  3.4  3.3   0.65\n",
       "           1      0.3  1.4  3.5  3.4   0.66\n",
       "           1      3.3  1.5  2.5  3.5   0.66\n",
       "2024-10-03 3      3.4  0.2  0.2  0.2   0.96\n",
       "           1      3.5  0.3  0.3  0.1   0.38"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "data = {\n",
    "    'f1': [0.1, 0.2, 0.3, 0.4, 0.5, 0.2, 0.3, 3.3, 3.4, 3.5],\n",
    "    'f2': [1.1, 1.2, 1.3, 3.3, 3.4, 3.5, 1.4, 1.5, 0.2, 0.3],\n",
    "    'm1': [2.1, 2.2, 2.3, 2.4, 3.3, 3.4, 3.5, 2.5, 0.2, 0.3],\n",
    "    'm2': [3.3, 3.4, 3.5, 3.1, 3.2, 3.3, 3.4, 3.5, 0.2, 0.1]\n",
    "}\n",
    "\n",
    "# Example index values (dates and IDs)\n",
    "index = pd.MultiIndex.from_tuples([\n",
    "    ('2024-10-01', '1'),\n",
    "    ('2024-10-01', '1'),\n",
    "    ('2024-10-01', '2'),\n",
    "    ('2024-10-01', '2'),\n",
    "    ('2024-10-01', '1'),\n",
    "    ('2024-10-02', '2'),\n",
    "    ('2024-10-02', '1'),\n",
    "    ('2024-10-02', '1'),\n",
    "    ('2024-10-03', '3'),\n",
    "    ('2024-10-03', '1'),\n",
    "], names=['date', 'ID_QI'])\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "df['c2cdr'] = np.random.rand(len(df))\n",
    "df['c2cdr'] = df['c2cdr'].groupby(['date', 'ID_QI']).mean().round(2) # make sure that the target is fixed for a given (date, ID_QI) pair\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['date', 'ID_QI'])\n",
    "\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for (date, ID_QI), group in grouped:\n",
    "    features = group[['f1', 'f2', 'm1', 'm2']].values\n",
    "    assert group['c2cdr'].nunique() == 1\n",
    "    target = group['c2cdr'].iloc[0]  # Single target for the group\n",
    "    \n",
    "    sequences.append(features)\n",
    "    targets.append(target)\n",
    "\n",
    "sequences = [torch.tensor(seq, dtype=torch.float32) for seq in sequences]\n",
    "targets = torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    embeddings = padded_sequences[:, :, :2]  # TODO: Select f1, f2 (embeddings)\n",
    "    meta_features = padded_sequences[:, :, 2:]  # TODO: Select m1, m2 (meta features)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "    targets = torch.tensor(targets, dtype=torch.float32)\n",
    "    return embeddings, meta_features, lengths, targets\n",
    "\n",
    "tweet_dataset = TweetDataset(sequences, targets)\n",
    "data_loader = DataLoader(tweet_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedTweetAttentionModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=2, meta_dim=2, mlp_dim=32):\n",
    "        super(BatchedTweetAttentionModel, self).__init__()\n",
    "        self.intermediary_layer = nn.Linear(embedding_dim + meta_dim, embedding_dim + meta_dim)\n",
    "        self.attention_layer = nn.Linear(embedding_dim + meta_dim, 1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, meta_features, lengths):\n",
    "        \"\"\"\n",
    "        embeddings: tensor of shape (batch_size, L_max, embedding_dim) (padded)\n",
    "        meta_features: tensor of shape (batch_size, L_max, meta_dim) (padded)\n",
    "        lengths: tensor of shape (batch_size,) indicating the actual length of each sequence\n",
    "        \"\"\"\n",
    "        batch_size, L_max, _ = embeddings.shape\n",
    "        concat_features = torch.cat([embeddings, meta_features], dim=-1)  # Shape: (batch_size, L_max, embedding_dim + meta_dim)\n",
    "        transformed_features = torch.tanh(self.intermediary_layer(concat_features))  # Shape: (batch_size, L_max, embedding_dim + meta_dim)\n",
    "        w_l = torch.sigmoid(self.attention_layer(transformed_features)).squeeze(-1)  # Shape: (batch_size, L_max)\n",
    "        mask = torch.arange(L_max).expand(batch_size, L_max) < lengths.unsqueeze(1)  # Shape: (batch_size, L_max)\n",
    "        mask = mask.to(embeddings.device)\n",
    "        w_l = w_l.masked_fill(~mask, -float('inf'))  # Mask out padded positions by setting large negative values\n",
    "        alpha_l = F.softmax(w_l, dim=1)  # Shape: (batch_size, L_max)\n",
    "        weighted_embedding = torch.sum(alpha_l.unsqueeze(-1) * embeddings, dim=1)  # Shape: (batch_size, embedding_dim)\n",
    "        prediction = self.mlp(weighted_embedding).squeeze(-1)  # Shape: (batch_size,)\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "class BatchedTweetAverageModel(nn.Module): # Only for comparison with the regular model\n",
    "    def __init__(self, embedding_dim=2, mlp_dim=32):\n",
    "        super(BatchedTweetAverageModel, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, 1)  # Final output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, lengths):\n",
    "        \"\"\"\n",
    "        embeddings: tensor of shape (batch_size, L_max, embedding_dim) (padded)\n",
    "        lengths: tensor of shape (batch_size,) indicating the actual length of each sequence\n",
    "        \"\"\"\n",
    "        batch_size, L_max, _ = embeddings.shape\n",
    "        mask = torch.arange(L_max).expand(batch_size, L_max).to(embeddings.device) < lengths.unsqueeze(1)  # Shape: (batch_size, L_max)\n",
    "        masked_embeddings = embeddings * mask.unsqueeze(-1)\n",
    "        sum_embeddings = masked_embeddings.sum(dim=1)  # Shape: (batch_size, embedding_dim)\n",
    "        avg_embeddings = sum_embeddings / lengths.unsqueeze(1).float()  # Shape: (batch_size, embedding_dim)\n",
    "        print(avg_embeddings)\n",
    "        prediction = self.mlp(avg_embeddings).squeeze(-1)  # Shape: (batch_size,)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2667, 1.9000],\n",
      "        [1.8000, 1.4500],\n",
      "        [3.5000, 0.3000],\n",
      "        [0.3500, 2.3000]])\n"
     ]
    }
   ],
   "source": [
    "model = BatchedTweetAttentionModel()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for embeddings, meta_features, lengths, target_batch in data_loader:\n",
    "    prediction = model(embeddings, meta_features, lengths)\n",
    "    loss = criterion(prediction, target_batch)\n",
    "    break\n",
    "\n",
    "\n",
    "# TODO: test if this model gives exactly the same results as the regular model\n",
    "model = BatchedTweetAverageModel()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for embeddings, meta_features, lengths, target_batch in data_loader:\n",
    "    prediction = model(embeddings, lengths)\n",
    "    loss = criterion(prediction, target_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 1.1000],\n",
       "         [0.2000, 1.2000],\n",
       "         [0.5000, 3.4000]],\n",
       "\n",
       "        [[0.3000, 1.4000],\n",
       "         [3.3000, 1.5000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[3.5000, 0.3000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3000, 1.3000],\n",
       "         [0.4000, 3.3000],\n",
       "         [0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat((embeddings, meta_features), dim=2)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5600, 0.6600, 0.3800, 0.5700])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8999999999999997"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1.1, 1.2, 3.4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
