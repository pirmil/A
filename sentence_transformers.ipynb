{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import transformers\n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121 4.42.4 3.0.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, transformers.__version__, sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_counts(sentences: list[str], tokenizer: transformers.PreTrainedTokenizer) -> list[int]:\n",
    "    \"\"\"\n",
    "    Return a list of token counts for each sentence.\n",
    "\n",
    "    Args:\n",
    "        sentences: A list of input sentences (strings).\n",
    "        tokenizer: A pre-trained tokenizer (e.g., BERT, RoBERTa).\n",
    "\n",
    "    Returns:\n",
    "        token_counts: A list of integers, where each element represents the number of tokens for the corresponding sentence.\n",
    "    \"\"\"\n",
    "    token_counts = [len(tokenizer.encode_plus(sentence, add_special_tokens=True)[\"input_ids\"]) for sentence in sentences]\n",
    "    return token_counts\n",
    "\n",
    "def get_word_counts(sentences: list[str]):\n",
    "    word_counts = [len(sentence.strip().split()) for sentence in sentences]\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.50494384765625, 64.03974151611328, 19.520017623901367]]\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.36.0\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "input_texts = [\n",
    "    \"what is the capital of China?\",\n",
    "    \"how to implement quick sort in python?\",\n",
    "    \"Beijing\",\n",
    "    \"sorting algorithms\"\n",
    "]\n",
    "\n",
    "model_path = 'Alibaba-NLP/gte-base-en-v1.5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).to('cuda')\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=8192, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = outputs.last_hidden_state[:, 0]\n",
    " \n",
    "# (Optionally) normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
    "print(scores.tolist())\n",
    "\n",
    "def get_embeddings(input_texts):\n",
    "    model.to('cuda')\n",
    "    batch_dict = tokenizer(input_texts, max_length=8192, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    embeddings = outputs.last_hidden_state[:, 0]\n",
    "    F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3450]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\.cache\\huggingface\\modules\\transformers_modules\\Alibaba-NLP\\new-impl\\fcceab01127c2ce888844aa365d3195cff389c7c\\modeling.py:578: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Requires sentence_transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "model_sentence = SentenceTransformer('Alibaba-NLP/gte-base-en-v1.5', trust_remote_code=True)\n",
    "embeddings_2 = model_sentence.encode(input_texts)\n",
    "print(cos_sim(embeddings_2[0], embeddings_2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001 , 0.34504956, 0.6403974 , 0.19520023],\n",
       "       [0.34504956, 1.0000001 , 0.21707077, 0.5514271 ],\n",
       "       [0.6403974 , 0.21707077, 1.0000002 , 0.12539631],\n",
       "       [0.19520023, 0.5514271 , 0.12539631, 1.0000006 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999994, 0.34504956, 0.64039755, 0.19520023],\n",
       "       [0.34504956, 1.0000002 , 0.2170707 , 0.55142707],\n",
       "       [0.64039755, 0.2170707 , 1.0000001 , 0.12539637],\n",
       "       [0.19520023, 0.55142707, 0.12539637, 1.0000002 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 12, 4922]\n",
      "[5, 7, 3641]\n"
     ]
    }
   ],
   "source": [
    "long_text = \"fAs a mathematician and physicist, he made many original fundamental contributions to pure and applied mathematics, mathematical physics, and celestial mechanics.[6] In his research on the three-body problem, Poincaré became the first person to discover a chaotic deterministic system which laid the foundations of modern chaos theory. He is also considered to be one of the founders of the field of topology. Early in the 20th century he formulated the Poincaré conjecture, which became, over time, one of the famous unsolved problems in mathematics. It was solved in 20022003 by Grigori Perelman.\"\n",
    "sentences = [\"This is a sample sentence.\", \"Another, slightly longer sentence with multiple tokens.\", long_text*40]\n",
    "token_counts = get_token_counts(sentences, tokenizer)\n",
    "print(token_counts)\n",
    "\n",
    "print(get_word_counts(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3518264213128262"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4922/3641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\n",
    "    \"what is the capital of China?\",\n",
    "    \"how to implement quick sort in python?\",\n",
    "    \"Beijing\",\n",
    "    \"sorting algorithms\",\n",
    "    long_text * 40\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.3450492 , 0.6403974 , 0.1952    , 0.28782588],\n",
       "       [0.3450492 , 1.0000001 , 0.21707052, 0.55142707, 0.26809558],\n",
       "       [0.6403974 , 0.21707052, 1.        , 0.12539633, 0.21799149],\n",
       "       [0.1952    , 0.55142707, 0.12539633, 1.0000005 , 0.20562805],\n",
       "       [0.28782588, 0.26809558, 0.21799149, 0.20562805, 0.9999999 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model_sentence.encode(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.3450492 , 0.6403974 , 0.1952    , 0.28782588],\n",
       "       [0.3450492 , 1.0000001 , 0.21707052, 0.55142707, 0.26809558],\n",
       "       [0.6403974 , 0.21707052, 1.        , 0.12539633, 0.21799149],\n",
       "       [0.1952    , 0.55142707, 0.12539633, 1.0000005 , 0.20562805],\n",
       "       [0.28782588, 0.26809558, 0.21799149, 0.20562805, 0.9999999 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = get_embeddings(input_texts)\n",
    "cosine_similarity(e.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
