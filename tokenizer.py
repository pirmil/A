from typing import List, Dict
import re
import emoji
from nltk.tokenize import TweetTokenizer
import spacy


EMOJI_MAPPING = {
    'ğŸ¤¤': 'drooling',
    'ğŸ˜‰': 'winking',
    'ğŸ˜': 'smirking',
    'ğŸ¤­': 'gossiping',
    'ğŸ˜š': 'kissing',
    'ğŸ˜˜': 'kissing',
    'ğŸ’–': 'love',
    'â¤ï¸': 'love',
    'ğŸ§¡': 'love',
    'ğŸ’™': 'love',
    'â™¥ï¸': 'love',
    'ğŸ’—': 'love',
    'ğŸ¤': 'love',
    'ğŸ¤': 'love',
    'ğŸ’œ': 'love',
    'ğŸ’š': 'love',
    'ğŸ¤Ÿ': 'love',
    'ğŸ¥°': 'love',
    'ğŸ˜': 'love',
    'ğŸ¤”': 'thinking',
    'ğŸ˜Œ': 'relieved',
    'ğŸ˜±': 'scared',
    'ğŸ˜¨': 'scared',
    'ğŸ’¢': 'angry',
    'ğŸ˜ ': 'angry',
    'ğŸ˜¤': 'angry',
    'ğŸ˜¡': 'angry',
    'ğŸ‘¿': 'angry',
    'ğŸ–•': 'angry',
    'ğŸ˜ˆ': 'naughty',
    'ğŸ¤—': 'hugging',
    'ğŸ¤£': 'laughing',
    'ğŸ˜‚': 'laughing',
    'ğŸ˜†': 'laughing',
    'ğŸ™‚': 'laughing',
    'ğŸ¤©': 'fascinated',
    'ğŸ¤©': 'fascinated',
    'ğŸ˜¶': 'speechless',
    'ğŸ˜®': 'shocked',
    'ğŸ˜²': 'shocked',
    'ğŸ¤¯': 'shocked',
    'ğŸ™„': 'disdain',
    'ğŸ˜´': 'sleepy',
    'ğŸ™„': 'annoyed',
    'ğŸ˜': 'expressionless',
    'ğŸ˜‘': 'expressionless',
    'ğŸ™ƒ': 'sarcasm',
    'ğŸ§': 'monocle',
    'ğŸ¤¨': 'perplexed',
    'ğŸ’€': 'skull',
    'â˜ ï¸': 'skull',
    'ğŸ˜¬': 'grimace',
    'ğŸ˜·': 'mask',
    'ğŸ˜¢': 'sad',
    'ğŸ˜­': 'sad',
    'ğŸ˜£': 'sad',
    'ğŸ¥º': 'sad',
    'ğŸ˜”': 'sad',
    'ğŸ˜Ÿ': 'sad',
    'ğŸ’”': 'disappointed',
    'ğŸ˜': 'disappointed',
    'ğŸ˜©': 'upset',
    'â˜¹ï¸': 'frowning',
    'ğŸ¤‘': 'money',
    'ğŸ’¸': 'money',
    'ğŸ’°': 'money',
    'ğŸ’µ': 'money',
    'ğŸ’³': 'money',
    'ğŸ¤“': 'nerd',
    'ğŸ¤¡': 'clown',
    'ğŸ·': 'pig',
    'ğŸ±': 'cat',
    'ğŸ': 'goat',
    'ğŸ™‡': 'bowing',
    'ğŸ™‡â€â™€ï¸': 'bowing',
    'ğŸ¤·': 'shrugging',
    'ğŸ¤·â€â™‚ï¸': 'shrugging',
    'ğŸ’â€â™€ï¸': 'assistance',
    'ğŸ™…â€â™€ï¸': 'disapproval',
    'ğŸ™…â€â™‚ï¸': 'disapproval',
    'ğŸ¤¦': 'facepalm',
    'ğŸ¤¦â€â™€ï¸': 'facepalm',
    'ğŸ¤¦â€â™‚ï¸': 'facepalm',
    'ğŸ™‹': 'question',
    'ğŸ™‹': 'question',
    'ğŸ˜ƒ': 'joy',
    'ğŸ˜Š': 'joy',
    'ğŸ˜€': 'joy',
    'ğŸ˜„': 'joy',
    'â˜ºï¸': 'joy',
    'ğŸ¤–': 'robot',
    'ğŸ‘½': 'alien',
    'ğŸ›¸': 'alien',
    'ğŸš€': 'rocket',
    'ğŸµ': 'music',
    'ğŸ¶': 'music',
    'ğŸ¥³': 'party',
    'ğŸŠ': 'party',
    'ğŸ‚': 'party',
    'ğŸ‰': 'party',
    'âœ¨': 'party',
    'ğŸ˜': 'sunglasses',
    'ğŸ˜‡': 'angel',
    'ğŸŒ': 'sun',
    'ğŸ™‰': 'covering ears',
    'ğŸ™ˆ': 'covering eyes',
    'ğŸ”’': 'padlock',
    'ğŸ’': 'ring',
    'ğŸ’': 'diamond',
    'ğŸ“–': 'book',
    'âš–ï¸': 'balance scale',
    'ğŸ’£': 'bomb',
    'ğŸ”«': 'gun',
    'ğŸ’¥': 'explosion',
    'ğŸ’¡': 'light bulb',
    'ğŸ’©': 'poop',
    'ğŸ—¿': 'stoic',
    'ğŸ‘€': 'eyes',
    'ğŸ’ª': 'flexing',
    'ğŸ¤²': 'praying',
    'ğŸ‘': 'clapping',
    'ğŸ‘Š': 'solidarity',
    'âœŠ': 'solidarity',
    'âœ–ï¸': 'disapproval',
    'âŒ': 'disapproval',
    'â': 'disapproval',
    'ğŸ’¯': 'approval',
    'âœ…': 'approval',
    'â˜‘ï¸': 'approval',
    'âœ”ï¸': 'approval',
    'ğŸ‘': 'approval',
    'ğŸ‘Œ': 'approval',
    'âœŒï¸': 'peace',
    'ğŸ¤': 'hoping',
    'ğŸ§ ': 'brain',
    'ğŸ†': 'victory',
    'ğŸ…': 'victory',
    'ğŸ¥‡': 'victory',
    'âš ï¸': 'warning',
    'ğŸ”¥': 'fire',
    'ğŸ”®': 'crystal ball',
    'ğŸ’¹': 'increasing',
    'ğŸ“ˆ': 'increasing',
    'ğŸ“‰': 'decreasing',
    'â„ï¸': 'snow',
    'ğŸ’§': 'water',
    'ğŸ’¦': 'water',
    'ğŸŒŠ': 'water wave',
}

STOP_WORDS = ['a', 'about', 'after', 'again', 'all', 'am', 'an', 'and', 'any', 'are', 'at',
    'b', 'be', 'because', 'been', 'before', 'being', 'but', 'by',
    'c', 'can', 
    'd', 'did', 'do', 'does', 'doing', 'don', 'down',
    'e', 'every', 'each',
    'f', 'for', 'from',
    'g',
    'h', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'him', 'his', 'how', "she'd", "he'd", "he'll", "she'll",
    'i', 'if', 'in', 'into', 'is', 'it', 'its', "it's", "it'll", "I'd", "I'll",
    'j', 'just',
    'k',
    'l', 'll',
    'm', 'more', 'most', 'my', 'me', 'myself',
    'n', 'now',
    'o', 'only', 'or', 'other', 'our', 'out', 'over',
    'p',
    'q',
    'r',
    's', 'same', 'she', 'should', 'so', 'some',
    't', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'to', 'too', "they'll", "they'd",
    'u', 'us',
    'v',
    'w', 'was', 'we', 'were', 'what', 'when', 'where', 'who', 'why', 'will', 'with', 'whom', 'whose', 'which',
    'x',
    'y', 'you', 'your', 'yourself', "you'll", "you'd",
    'z',
]

class CustomTokenizer:
    def __init__(self, stop_words: List[str], emoji_mapping: Dict[str, str], remove_urls=True, tokenizer='tweet_tokenizer'):
        self.emoji_mapping = emoji_mapping
        self.remove_urls = remove_urls
        self.tokenizer = tokenizer
        if tokenizer == 'tweet_tokenizer':
            self.tweet_tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True, match_phone_numbers=False)
        self.stop_words = stop_words

    def __call__(self, text: str):
        text = self.process_urls(text, self.remove_urls)
        text = self.process_emojis(text, self.emoji_mapping)
        tokens = self.tokenize(text, self.tokenizer)
        return tokens
    

    def tokenize(self, text: str, tokenizer: str):
        if tokenizer == 'tweet_tokenizer':
            tokens = self.tweet_tokenizer.tokenize(text)
            tokens = [token for token in tokens if token not in self.stop_words]
            return tokens

    def process_urls(self, text: str, remove=True, url_token='URL'):
        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        if remove:
            return re.sub(url_pattern, '', text)
        return re.sub(url_pattern, url_token, text)

    def normalize_whitespace(self, text: str):
        return re.sub(r'\s+', ' ', text)

    def process_emojis(self, text: str, emoji_mapping: dict):
        for emoj, value in emoji_mapping.items():
            text = text.replace(emoj, f' {value} ')
        # Remove any remaining emoji
        text = emoji.replace_emoji(text, '')
        text = self.normalize_whitespace(text)
        return text
    
custom_tokenizer = CustomTokenizer(STOP_WORDS, EMOJI_MAPPING)
text = "Check checked checks this outğŸµğŸ”¥ğŸ¤¤â¤ï¸! ğŸ¤¦Checking âš–ï¸ğŸµtim@gmail.com ğŸâ¤ï¸ $11 http://example.com #Covid19 #Amazing #IAmHappyğŸµğŸ”¥ğŸ¤¤â¤ï¸ğŸµ @elonmusk $Tesla.ğŸ³ï¸â€ğŸŒˆ It's not what you'll  think @r@a! $TSLA she isn't happy"
print(text)
tokenized_text = ' '.join(custom_tokenizer(text))
tokenized_text

nlp = spacy.load('en_core_web_sm')
tokens = [token.lemma_ for token in nlp(tokenized_text) if token.lemma_ not in STOP_WORDS]
' '.join(tokens)
